{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Immesive Final Project (General Assembly ATX Spring 2017)\n",
    "The data for my final project was obtained from the Appalachian Trail Conservancy (Harpers Ferry,WV).\n",
    "\n",
    "### Final Project Question: Can you predict how long it will take a thru hike to complete the Appalachian Trail based on the features of this dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to concatenate this dataset with weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Table of Content: \n",
    "I explore the data column by column to understand what sort of missing or inaccurate values are contained.\n",
    "\n",
    "def (clean_1): Columns that can/will be dropped\n",
    "- Rename columns to be more accurate.\n",
    "- Drop 'Days Elapsed' column as it does not accuratly calculate the number of days on trail. (I replace this column in clean_2 with 'Total_Days')\n",
    "- Drop 'Hiking_Disability' Column as it was not well reported\n",
    "- Drop Dog Weight Column (16238 of possible 17835 values were 0)\n",
    "- Drop columns with too many null values (columns that exceed 85 percent null values)\n",
    "- drop null values out of columns\n",
    "- **** come back to this Drop Under2kAmount column since (16125 out of 17835) values were 0 essentially the same as null values \n",
    "- Dropped 'Hiking \n",
    "\n",
    "\n",
    "def (clean_2/clean_3): Clean up the Age column \n",
    "- Fill null values in 'Age' column with median age.\n",
    "- All values below 4(There were some negative values) \n",
    "- The youngest person to thru-hike the AT is 5 so I assume all values above this are \n",
    "\n",
    " \n",
    "    \n",
    "def (clean_4): Datetime objects, \n",
    "-  Convert 'Start' and 'Finish' columns to Datetime objects\n",
    "-  Create a new column 'Total Days' that calculates total days on trail (at['Finish] - at['Start'])) \n",
    "-  There was as single null value in completion year, however, the finish date showed the hiker completed in 2016 so I changed the value to 2016 \n",
    "- I conveted the completion yr column from floats to ints \n",
    "- converted completion yr to a datetime object\n",
    "\n",
    "\n",
    "\n",
    "def (clean_5/clean_6): Clean 'Sex' column\n",
    "- In (clean_1) I dropped all null values in this column \n",
    "- Drop 'oher' and 'othe' out of the sex column\n",
    "- Convert the 'Sex' column to numerical format with the map function\n",
    "- Drop null values in the Sex column. There were only 2. \n",
    "- Converted M/F from float to int\n",
    "\n",
    "def (clean_7/clean_8): Clean 'Hike_Type' column (Drop section, alternative hikes, Yo Yo)\n",
    "- Drop values in the Hike column that are labeled alternative as I am unsure what these are and how to define them.\n",
    "- Since I am only interested in Thru Hikers and trying to predict time on trail based on people trying to hike in 6 months, and since all thru section hikers take varying amounts of time. \n",
    "- Difficult to estimate value for a Yo Yo so I dropped it, it was only a single column\n",
    "\n",
    "def (clean_9): Categorize the race column:\n",
    "- 'Prefer not to say' = 0\n",
    "- []\n",
    "    \n",
    "\n",
    "\n",
    "def (clean_10): Reset Index \n",
    "- The index needed to be reset since I had dropped many rows containing null values \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do \n",
    "\n",
    "3.) Make Boolean columns into dummy variables \n",
    "\n",
    "5.) Yo Yo split that into 1 Northbound and 1 southbound. \n",
    "\n",
    "6.) Race \n",
    "\n",
    "7.) State \n",
    "\n",
    "8.) There are negative total days (str.replace values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at = pd.read_excel('BenHikersInfo.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_1(df):\n",
    "    df.drop(labels = df[['Disease Other','School','Hiking Disability','DogWeightLbs','Days Elapsed','MinorityComments','School',\n",
    "                         'DogBreed','Disability','Under2KAmount']], axis = 1, inplace = True)\n",
    "    df.rename(columns = {'AgeYrFin': 'Age','Race or Heritage': 'Race',\n",
    "                        'StAbbrev':'State', 'Hiking Disability ': 'Hiking_Disability', \n",
    "                         'Hike Type': 'Hike_Type', 'Yr Comp':'completion_yr',\n",
    "                         },inplace = True)\n",
    "    df.dropna(subset= ['Start','Sex','Race','Country','State','Hike_Type'],inplace = True)\n",
    "\n",
    "clean_1(at)  \n",
    "\n",
    "\n",
    "def clean_2(df):\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "clean_2(at)\n",
    "\n",
    "\n",
    "def clean_3(x,median_age): \n",
    "    if x < 4:\n",
    "        return median_age\n",
    "    else:\n",
    "        return x \n",
    "at['Age'] = at['Age'].apply(lambda x: clean_3(x, at['Age'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_4(df):\n",
    "    df['Finish'] = pd.to_datetime(df['Finish'])\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['Total_Days'] = df['Finish'] - df['Start']\n",
    "    df['completion_yr'].fillna(2016,inplace = True)\n",
    "    df['completion_yr'] = df['completion_yr'].astype(int)\n",
    "clean_4(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_5(df):\n",
    "    df['Sex'] = df['Sex'].map({'M':0,'F':1})\n",
    "    to_drop = ['othe','Oher']\n",
    "    x = df[df['Sex'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_5(at)\n",
    "\n",
    "def clean_6(df):\n",
    "    df.dropna(subset = ['Sex'], inplace = True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "clean_6(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_7(df):\n",
    "    to_drop = ['Alternative','alternative','Alterntive', 'Yo Yo']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_7(at)\n",
    "\n",
    "def clean_8(df):\n",
    "    to_drop = ['Section']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_8(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_9(df):\n",
    "    # Prefer not to say: 0\n",
    "    df['Race'] = df['Race'].replace(['Prefer not to say','Other'], 0)\n",
    "    # Caucasion Variation: 1\n",
    "    df['Race'] = df['Race'].replace(['White','WASP','Irish','Hewbrew/White','English','Caucasian / Viking',\n",
    "                                    'Caucasian or White','Caucasian or White/Irish','Caucasian / Polish / Irish',\n",
    "                                    'Caucasian / South Africaan','Caucasian or White/Amish',\n",
    "                                     'Caucasian or White/Jewish',\n",
    "                                    ], 1)\n",
    "    # African American Variation: 2\n",
    "    df['Race'] = df['Race'].replace(['African American'], 2)\n",
    "    # Asian Variation: 3\n",
    "    df['Race'] = df['Race'].replace(['Asian','Chinese','Asian / Chinese','Vietnamese'], 3)\n",
    "    # Hispanic Variation: 4\n",
    "    df['Race'] = df['Race'].replace('Hispanic', 4)\n",
    "    # Native American Variation\n",
    "    \n",
    "    \n",
    "\n",
    "clean_9(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6856,\n",
       "         1: 5556,\n",
       "         2: 17,\n",
       "         'No Application - Letter Only': 1,\n",
       "         'American Indian / Caucasian': 7,\n",
       "         'not hispanic or latino': 42,\n",
       "         'European/Native American': 1,\n",
       "         'African American/Biracial': 1,\n",
       "         'Cherokee & English': 1,\n",
       "         3: 36,\n",
       "         'Caucasian or White/Pacific Islander': 1,\n",
       "         'European/American': 1,\n",
       "         4: 36,\n",
       "         'Irish/Italian': 1,\n",
       "         'Romanian': 1,\n",
       "         'Irish/American': 1,\n",
       "         'Hispanic/Black': 1,\n",
       "         'Irish American': 2,\n",
       "         'Swiss': 1,\n",
       "         'German/Irish American': 1,\n",
       "         'Swiss/American': 1,\n",
       "         'Mixed': 2,\n",
       "         'Jewish/White': 1,\n",
       "         'Western European / American': 1,\n",
       "         'African / European / Carribean': 1,\n",
       "         'Viking': 1,\n",
       "         'European / American': 1,\n",
       "         'Asian / American': 3,\n",
       "         'Caucasian / Italian / Eastern European': 1,\n",
       "         'Mexican / American': 1,\n",
       "         'Not on Application': 1,\n",
       "         'Japanese-American': 1,\n",
       "         'German': 3,\n",
       "         'Caucasian or White (Jewish)': 1,\n",
       "         'Appalachian / American': 2,\n",
       "         'Caucasian / Irish': 3,\n",
       "         'Canadian': 1,\n",
       "         'Western European': 1,\n",
       "         'mixed': 1,\n",
       "         'Taiwanese / American': 1,\n",
       "         'Anglo Saxon / Scottish / American': 1,\n",
       "         'Caucasian / Black / West Indian': 1,\n",
       "         'Irish/Italian/English/Dutch': 1,\n",
       "         'European': 5,\n",
       "         'Black/White': 1,\n",
       "         'Elf': 1,\n",
       "         'Dutch': 3,\n",
       "         'Cuban': 1,\n",
       "         'Not Hispanic of Latino': 2,\n",
       "         'Caucasian / Brazilian': 1,\n",
       "         'Caucasian / European': 2,\n",
       "         'Polish': 2,\n",
       "         'Japanese': 1,\n",
       "         'Not Hispanice or Latino': 1,\n",
       "         'Ukrainian': 2,\n",
       "         'British or English': 1,\n",
       "         'Latino / Venzuelan': 1,\n",
       "         'Pacific Islander': 3,\n",
       "         'Italian': 2,\n",
       "         'English / Irish': 1,\n",
       "         'Caucasian / Chinese': 1,\n",
       "         'Mexican': 2,\n",
       "         'Irish / Scottish / German': 1,\n",
       "         'Yugoslav / Swedish': 1,\n",
       "         'Finnish': 1,\n",
       "         'White/Jewish': 1,\n",
       "         'Dominican': 1,\n",
       "         'Japanese / Scandinavian': 1,\n",
       "         'Mexican/American': 1,\n",
       "         'other': 1,\n",
       "         'Not hispanic or Latino': 5,\n",
       "         'Black / Caucasian': 1,\n",
       "         'Chinese / German': 1,\n",
       "         'Latino/White': 1,\n",
       "         'Not hispanic or Lation': 2,\n",
       "         'Caucasian / Slovak': 1,\n",
       "         'German / American': 2,\n",
       "         'Korean/American': 1,\n",
       "         'German / Slovak': 1,\n",
       "         'Alaska Native': 1,\n",
       "         'Korean': 6,\n",
       "         'Hawaiian': 1,\n",
       "         'Korean / English': 1,\n",
       "         'White/Asian': 2,\n",
       "         'Mexican/Greek': 1,\n",
       "         'Eastern European': 2,\n",
       "         'Mutt': 2,\n",
       "         'WASP / Italian': 1,\n",
       "         'Thai': 1,\n",
       "         'Melungeon': 1,\n",
       "         'French Acadian': 1,\n",
       "         'Indian': 3,\n",
       "         'Angelic': 1,\n",
       "         'White/Pennsylvania Dutch': 1,\n",
       "         'Caucasian / Polish': 1,\n",
       "         'Hispanic or Latino': 2,\n",
       "         'Scotttish/Irish/Norwegian': 1,\n",
       "         'Puerto Rican': 1,\n",
       "         'Caucasian / Philipino': 1,\n",
       "         'Caucasian / Jewish': 1,\n",
       "         'Not Hispanic or Latino': 30,\n",
       "         'Japanese / American': 2,\n",
       "         'White/Lebanese': 1,\n",
       "         'Hispanic or Latino; Mixed': 1,\n",
       "         'White/Native American': 3,\n",
       "         'Italian / French': 1,\n",
       "         'Tamil/Sri Lankan': 1,\n",
       "         'Italian / Portuguese / American': 1,\n",
       "         'Caucasian / Asian': 4,\n",
       "         'Caucasian/Hispanic': 2,\n",
       "         'Not Hispnic or Latino': 1,\n",
       "         'White/Latina': 1,\n",
       "         'Texan': 1,\n",
       "         'Native American': 8,\n",
       "         'American Indian': 12,\n",
       "         'Caucasian': 2,\n",
       "         'Pakistani': 1,\n",
       "         'not hispanice or latino': 1,\n",
       "         'Hispanic/White': 1,\n",
       "         'Not Hispanic or latino': 1,\n",
       "         'French Canadian': 1,\n",
       "         'german': 1,\n",
       "         'Scandinavian': 1,\n",
       "         'Asian American': 2,\n",
       "         'Native American (1/2 cherokee) / 1/2 Celtic': 1,\n",
       "         'Caucasion/Filipino': 1,\n",
       "         'American': 37,\n",
       "         'Spanish/Italian': 1,\n",
       "         'African American/American Indian': 1,\n",
       "         'not latino or hispanic': 1,\n",
       "         'Vikng': 1,\n",
       "         'Bulgarian': 1,\n",
       "         'Vietnamese American': 1,\n",
       "         'White/Hispanic': 1,\n",
       "         'Japanese/American': 1,\n",
       "         'nor hispanic or latino': 1,\n",
       "         'American Mutt': 1,\n",
       "         'European American': 2,\n",
       "         'white/hispanic': 1,\n",
       "         'Not Hispanic or Lation': 4,\n",
       "         'French Canadian/American': 1,\n",
       "         'Middle Easter/White': 1,\n",
       "         'White - Irish, Scot and Spanish': 1,\n",
       "         'British / American': 1,\n",
       "         'Scottish-German': 1,\n",
       "         'American Indian / Choctaw': 1,\n",
       "         'French-Canadian': 1,\n",
       "         'Scot - Irish': 1,\n",
       "         'Hispanic / Caucasian': 1,\n",
       "         'White & African American': 1,\n",
       "         'Scottish': 1,\n",
       "         'Hispanic / Mexican / American': 1,\n",
       "         'Appalachian American': 1,\n",
       "         'Italian American': 1,\n",
       "         'Caucasian / Haitian': 1,\n",
       "         'Persian': 1,\n",
       "         'European Mutt': 1,\n",
       "         'Jewish': 1,\n",
       "         'Pennsylvania Dutch': 1,\n",
       "         'Irish / American': 4,\n",
       "         'White/Scandinavian': 1,\n",
       "         'Asian / Pacific Islander / Hispanic': 1,\n",
       "         'Caucasian / Asian / Pacific Islander': 1,\n",
       "         'Korean / American': 2,\n",
       "         'Hispanic / Italian': 1,\n",
       "         'Japanese/White': 1,\n",
       "         'Asian / Chinese': 1,\n",
       "         'White/Irish': 2,\n",
       "         'Caucasian/French Canandien': 1,\n",
       "         'Irish / Mexican': 1,\n",
       "         'Yankee': 1,\n",
       "         'Other': 4,\n",
       "         'Black and White': 1,\n",
       "         'Caucasian / German': 1,\n",
       "         'Middle Eastern': 3,\n",
       "         'Lithuanian': 1,\n",
       "         'Filipino/Caucasian': 1,\n",
       "         'Vietnamese': 1,\n",
       "         'Lebanese / American': 1,\n",
       "         'American Indian / Cherokee': 2,\n",
       "         'Hispanic/German': 1,\n",
       "         'Caucasian / Bahamian': 1,\n",
       "         'Latino': 5,\n",
       "         'Caucasian / 1/4 German': 5,\n",
       "         'Spanish': 2,\n",
       "         'Polsih American': 1,\n",
       "         'Irish/Spanish': 1,\n",
       "         'Caucasian / Pacific Islander': 1,\n",
       "         'Hispanic / Mexican': 1,\n",
       "         'Caucasian / Hispanic': 2,\n",
       "         'Not hispanic or latino': 17,\n",
       "         'Human': 3,\n",
       "         'Caucasian / Czech / Russian / German / English)': 1,\n",
       "         'Asian (Indian/American)': 1,\n",
       "         'Caucasian / Irish / Nordic': 1,\n",
       "         'North European': 1,\n",
       "         'Mix': 14,\n",
       "         'Mennowhite': 1,\n",
       "         'Lebanese French Canadian': 1,\n",
       "         'Brazilian': 1,\n",
       "         'Caucasian / non-Hispanic': 2,\n",
       "         'Caucasian/Lithuanian-American': 1,\n",
       "         'not hispanic or lation': 1,\n",
       "         'Chinese/German': 1,\n",
       "         'Navajo / Portugese': 1,\n",
       "         'Hispanic  / Colombian': 1,\n",
       "         'Anglo Saxon': 2,\n",
       "         'Caucasian/Pacific Islander': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(at['Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_10(df):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "clean_10(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finish</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Country</th>\n",
       "      <th>Hike_Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>completion_yr</th>\n",
       "      <th>HikedWDog</th>\n",
       "      <th>WinterHike</th>\n",
       "      <th>Under2KSpent</th>\n",
       "      <th>SchoolCredit</th>\n",
       "      <th>Minority</th>\n",
       "      <th>Vegetarian</th>\n",
       "      <th>DehydrateOwnFood</th>\n",
       "      <th>Giardia</th>\n",
       "      <th>Lyme</th>\n",
       "      <th>Norovirus</th>\n",
       "      <th>Total_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-12-31</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951-10-10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>SOBO</td>\n",
       "      <td>1951-05-30</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>133 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951-09-30</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>1951-05-31</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>122 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-09-17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>1959-05-23</td>\n",
       "      <td>1959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>117 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965-09-23</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>SOBO</td>\n",
       "      <td>1965-04-16</td>\n",
       "      <td>1965</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>160 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Finish   Age                Race State  Sex Country Hike_Type  \\\n",
       "0 1948-12-31  29.0                   0    PA    0     USA      NOBO   \n",
       "1 1951-10-10  28.0                   0    CT    0     USA      SOBO   \n",
       "2 1951-09-30  29.0                   0    GA    0     USA      NOBO   \n",
       "3 1959-09-17  20.0  Caucasian or White    GA    0     USA      NOBO   \n",
       "4 1965-09-23  29.0                   0    PA    0     USA      SOBO   \n",
       "\n",
       "       Start  completion_yr HikedWDog WinterHike Under2KSpent SchoolCredit  \\\n",
       "0 1948-01-01           1948     False      False        False        False   \n",
       "1 1951-05-30           1951     False      False        False        False   \n",
       "2 1951-05-31           1951     False      False        False        False   \n",
       "3 1959-05-23           1959     False      False        False        False   \n",
       "4 1965-04-16           1965     False      False        False        False   \n",
       "\n",
       "  Minority Vegetarian DehydrateOwnFood Giardia   Lyme Norovirus  Total_Days  \n",
       "0    False      False            False   False  False     False    365 days  \n",
       "1    False      False            False   False  False     False    133 days  \n",
       "2    False      False            False   False  False     False    122 days  \n",
       "3    False      False            False   False  False     False    117 days  \n",
       "4    False      False            False   False  False     False    160 days  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() missing 2 required positional arguments: 'pat' and 'repl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9487a118673e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Race'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: replace() missing 2 required positional arguments: 'pat' and 'repl'"
     ]
    }
   ],
   "source": [
    "at['Race'].str.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def (clean_9): Categorize the race column:\n",
    "- 'Prefer not to say' = 0\n",
    "- Caucasion variation = 1\n",
    "- African American Variation = 2\n",
    "- Asian Variation = 3\n",
    "- Hispanic Variation = 4\n",
    "- \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop anything that is not a clearly identifiable race (i.e American is not a race)\n",
    "def clean_9(df):\n",
    "    df['Race'] = df['Race'].str.replace('Prefer not to say', '0')\n",
    "\n",
    "clean_9(at)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "at['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "at.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10,10))\n",
    "#null.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Null values by column \n",
    "#plt.figure(figsize = (10,10))\n",
    "#z = at.isnull().sum()\n",
    "#z.plot(kind = 'bar')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
