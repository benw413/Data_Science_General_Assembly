## Data Science Immersive Projects

Hello World! This repository contains multiple projects from my Data Science Immersive course at General Assembly.
The first project I have posted in this repository is a series of three separate Jupyter notebooks containing a progression from basic data analysis workflow to professional level workflow using machine learning in conjunction with the Titanic dataset from Kaggle.com. The purpose for these notebooks are to serve as a tutorial for how to progress from the basics of descriptive analytics to the more advanced techniques of machine learning. Over three separate Jupyter notebooks, I cover a step by step breakdown of how to explore, clean, analyze, visualize, and predict survival for Titanic passengers. I will demonstrate everything from importing libraries to uploading your predictions to Kaggle in a format that it will accept. Finally, I will also demonstrate how to automate workflow using pipelines to make code re-useable.

If you would like to learn more info about my Data Science Experience please feel free to check out my Blog at https://medium.com/@benweinstein_52172


#### Series 1: Data Analysis with the Titanic
This notebook uses pandas to explore, clean, analyze, and visualize basic information about the Titanic dataset and includes findings related to survival based on age, gender, class, and a host of other characteristics.

#### Series 2: Logistic Regression w/out Pipelines and how to upload predictions to Kaggle.com
This is a step by step guide to cleaning a dataset, manipulating the features, creating a logistic regression model, obtaining predictions, and passing the dataset into a pandas dataframe to upload to Kaggle. As you will see, my process is very step by step to help with visualization however not extremely reusable. I will explain how to make my code reusable in the next series with pipelines.

#### Series 3: Logistic Regression with pipelines: How to automate workflow
In this third and final jupyter notebook I will demonstrate how to use pipelines to allow for code to be re-useable. I will also upload this final dataset to Kaggle.com and report back a score. 


I will continue to add more content to this ReadMe file as I continue to create new projects.  
