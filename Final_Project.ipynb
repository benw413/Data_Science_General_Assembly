{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Immesive Final Project (General Assembly ATX Spring 2017)\n",
    "The data for my final project was obtained from the Appalachian Trail Conservancy (Harpers Ferry,WV).\n",
    "\n",
    "### Final Project Question: Can you predict how long it will take a thru hike to complete the Appalachian Trail based on the features of this dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Table of Content: \n",
    "I explore the data column by column to understand what sort of missing or inaccurate values are contained.\n",
    "\n",
    "def (clean_1): Columns that can/will be dropped\n",
    "- Rename columns to be more accurate.\n",
    "- Drop 'Days Elapsed' column as it does not accuratly calculate the number of days on trail. (I replace this column in clean_2 with 'Total_Days')\n",
    "- Drop 'Hiking_Disability' Column as it was not well reported\n",
    "- Drop Dog Weight Column (16238 of possible 17835 values were 0)\n",
    "- Drop columns with too many null values (columns that exceed 85 percent null values)\n",
    "- drop null values out of columns\n",
    "- **** come back to this Drop Under2kAmount column since (16125 out of 17835) values were 0 essentially the same as null values \n",
    "- Dropped 'Hiking \n",
    "\n",
    "\n",
    "def (clean_2/clean_3): Clean up the Age column \n",
    "- Fill null values in 'Age' column with median age.\n",
    "- All values below 4(There were some negative values) \n",
    "- The youngest person to thru-hike the AT is 5 so I assume all values above this are \n",
    "\n",
    " \n",
    "    \n",
    "def (clean_4): Datetime objects, \n",
    "-  Convert 'Start' and 'Finish' columns to Datetime objects\n",
    "-  Create a new column 'Total Days' that calculates total days on trail (at['Finish] - at['Start'])) \n",
    "-  There was as single null value in completion year, however, the finish date showed the hiker completed in 2016 so I changed the value to 2016 \n",
    "- I conveted the completion yr column from floats to ints \n",
    "- converted completion yr to a datetime object\n",
    "\n",
    "\n",
    "\n",
    "def (clean_5/clean_6): Clean 'Sex' column\n",
    "- In (clean_1) I dropped all null values in this column \n",
    "- Drop 'oher' and 'othe' out of the sex column\n",
    "- Convert the 'Sex' column to numerical format with the map function\n",
    "- Drop null values in the Sex column. There were only 2. \n",
    "- Converted M/F from float to int\n",
    "\n",
    "def (clean_7/clean_8): Clean 'Hike_Type' column (Drop section, alternative hikes, Yo Yo)\n",
    "- Drop values in the Hike column that are labeled alternative as I am unsure what these are and how to define them.\n",
    "- Since I am only interested in Thru Hikers and trying to predict time on trail based on people trying to hike in 6 months, and since all thru section hikers take varying amounts of time. \n",
    "- Difficult to estimate value for a Yo Yo so I dropped it, it was only a single column\n",
    "\n",
    "def (clean_9): Categorize the race column: Since the Data Set was very disorganized, Regular Expression\n",
    "was unable to take care of the categorization so I had to manually manipulate the categories\n",
    "- Caucasion variation = 0\n",
    "- African American Variation = 1\n",
    "- Asian Variation = 2\n",
    "- Hispanic Variation = 3\n",
    "- Native American = 4\n",
    "- Mixed Race: =5\n",
    "- European = 6\n",
    "- Mixed Race  = 7\n",
    "- European/Not American (You cannot assume they are white because they are European) = 8\n",
    "- Other = 9\n",
    "    \n",
    "\n",
    "def(clean_10): Group country of origin to express if they are North American, European, Australian,etc...\n",
    "- North American = 0 \n",
    "- European = 1 \n",
    "- Oceania = 2\n",
    "- African = 3\n",
    "\n",
    "def(clean_11): Convert Hike_Type values to numbers\n",
    "- 'NOBO':0\n",
    "- 'SOBO':1 \n",
    "- 'Flip':2 \n",
    "\n",
    "def (clean_12): Reset Index \n",
    "- The index needed to be reset since I had dropped many rows containing null values \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do \n",
    "\n",
    "3.) Make Boolean columns into dummy variables \n",
    "\n",
    "7.) State \n",
    "\n",
    "8.) There are negative total days (str.replace values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at = pd.read_excel('BenHikersInfo.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_1(df):\n",
    "    df.drop(labels = df[['Disease Other','School','Hiking Disability','DogWeightLbs','Days Elapsed','MinorityComments','School',\n",
    "                         'DogBreed','Disability','Under2KAmount']], axis = 1, inplace = True)\n",
    "    df.rename(columns = {'AgeYrFin': 'Age','Race or Heritage': 'Race',\n",
    "                        'StAbbrev':'State', 'Hiking Disability ': 'Hiking_Disability', \n",
    "                         'Hike Type': 'Hike_Type', 'Yr Comp':'completion_yr',\n",
    "                         },inplace = True)\n",
    "    df.dropna(subset= ['Start','Sex','Race','Country','State','Hike_Type'],inplace = True)\n",
    "\n",
    "clean_1(at)  \n",
    "\n",
    "\n",
    "def clean_2(df):\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "clean_2(at)\n",
    "\n",
    "\n",
    "def clean_3(x,median_age): \n",
    "    if x < 4:\n",
    "        return median_age\n",
    "    else:\n",
    "        return x \n",
    "at['Age'] = at['Age'].apply(lambda x: clean_3(x, at['Age'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_4(df):\n",
    "    df['Finish'] = pd.to_datetime(df['Finish'])\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['Total_Days'] = df['Finish'] - df['Start']\n",
    "    df['completion_yr'].fillna(2016,inplace = True)\n",
    "    df['completion_yr'] = df['completion_yr'].astype(int)\n",
    "clean_4(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_5(df):\n",
    "    df['Sex'] = df['Sex'].map({'M':0,'F':1})\n",
    "    to_drop = ['othe','Oher']\n",
    "    x = df[df['Sex'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_5(at)\n",
    "\n",
    "def clean_6(df):\n",
    "    df.dropna(subset = ['Sex'], inplace = True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "clean_6(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_7(df):\n",
    "    to_drop = ['Alternative','alternative','Alterntive', 'Yo Yo']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_7(at)\n",
    "\n",
    "def clean_8(df):\n",
    "    to_drop = ['Section']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_8(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall to maintain original column \n",
    "def clean_9(df):\n",
    "    \n",
    "    # Caucasion Variation: 0 Identify Race Over Nationality/Religion \n",
    "    df['Race'] = df['Race'].replace(['White','WASP','Hewbrew/White','English','Caucasian / Viking',\n",
    "                                    'Caucasian or White','Caucasian or White/Irish','Caucasian / Polish / Irish',\n",
    "                                    'Caucasian / South Africaan','Caucasian or White/Amish','Caucasian / Irish'\n",
    "                                     'Caucasian or White/Jewish','Caucasian / Irish',\n",
    "                                     'Anglo Saxon / Scottish / American','Caucasian or White (Jewish)',\n",
    "                                     'Caucasian / European','Caucasian or White/Pacific Islander','Jewish/White',\n",
    "                                     'Caucasian or White/Jewish','Caucasian / non-Hispanic',\n",
    "                                     'Caucasian / Czech / Russian / German / English)','Anglo Saxon','White/Irish',\n",
    "                                     'White/Jewish','Caucasian/Lithuanian-American','White/Scandinavian','Caucasian',\n",
    "                                     'White/Pennsylvania Dutch','Caucasian / Irish / Nordic','Caucasian / Jewish',\n",
    "                                     'European/American', 'Caucasian / Polish','Caucasian / German',\n",
    "                                     'Caucasian / 1/4 German', 'Caucasian/French Canandien','Caucasian / Slovak','Mennowhite',\n",
    "                                     'White/Lebanese', 'White - Irish, Scot and Spanish', 'Caucasian / Italian / Eastern European',\n",
    "                                     'Caucasian / Bahamian', 'Caucasian / Haitian'], 0)\n",
    "    # African American Variation: 1\n",
    "    df['Race'] = df['Race'].replace(['African American','African American/Biracial',], 1)\n",
    "    \n",
    "    # Asian Variation: 2\n",
    "    df['Race'] = df['Race'].replace(['Asian','Chinese','Asian / Chinese','Vietnamese','Thai',\n",
    "                                    'Taiwanese / American','Asian / American','Korean/American','Japanese',\n",
    "                                    'Indian','Asian American','Korean / American','Asian (Indian/American)',\n",
    "                                    'Middle Eastern','Korean','Japanese/American','Caucasian / Asian / Pacific Islander',\n",
    "                                     'American Indian', 'Vietnamese American','Persian','Japanese / American', 'Pakistani',\n",
    "                                     'Tamil/Sri Lankan', 'Pacific Islander', 'Caucasian / Asian'], 2)\n",
    "    # Hispanic/Latino: 3 I prioritize race over nationality \n",
    "    df['Race'] = df['Race'].replace(['Hispanic','Latino / Venzuelan','Japanese-American','Mexican / American',\n",
    "                                    'Mexican','Hispanic  / Colombian','Cuban','Latino','Puerto Rican',\n",
    "                                     'Hispanic or Latino','Mexican/American','Dominican','Hispanic / Mexican',\n",
    "                                    'Brazilian','Hispanic / Mexican / American','Hispanic/German', 'Hispanic / Italian',\n",
    "                                    ], 3)\n",
    "    # Native American Variation: 4\n",
    "    df['Race'] = df['Race'].replace(['American Indian / Cherokee','Cherokee & English','Native American',\n",
    "                                    'Native American (1/2 cherokee) / 1/2 Celtic','American Indian / Choctaw'],4)\n",
    "    \n",
    "    # Mixed Race: 5 (remember to look at this in relation to all the mixed white people/lation peop)\n",
    "    df['Race'] = df['Race'].replace(['Mixed','mixed','Caucasian / Black / West Indian','Hispanic/Black','Black/White',\n",
    "                                    'Mix','Black and White','white/hispanic','White/Hispanic',\n",
    "                                     'Mutt','Black / Caucasian','European Mutt','White/Asian',\n",
    "                                     'White & African American','Caucasian / Chinese', 'Caucasian / Philipino',\n",
    "                                     'Hispanic or Latino; Mixed','Japanese/White','White/Latina','Hispanic/White',\n",
    "                                     'Latino/White', 'Caucasian/Hispanic','Hispanic / Caucasian','Caucasian/Pacific Islander',\n",
    "                                     'Filipino/Caucasian', 'African American/American Indian','White/Native American',\n",
    "                                     'Middle Easter/White', 'European/Native American', 'Caucasian / Brazilian',\n",
    "                                     'Asian / Pacific Islander / Hispanic', 'Caucasian / Hispanic', 'Caucasion/Filipino',\n",
    "                                     'American Indian / Caucasian', 'Lebanese / American','Caucasian / Pacific Islander',\n",
    "                                     'Navajo / Portugese','WASP / Italian'], 5)\n",
    "    \n",
    "    # European: 6 (You cannot assume they are white because they are European)\n",
    "    df['Race'] = df['Race'].replace(['German','Italian','Polish','Dutch','European','Swiss','North European',\n",
    "                                    'Canadian','Finnish','german','Scottish','Ukrainian',\n",
    "                                    'Romanian','Bulgarian','Spanish','Lithuanian','British or English','Scandinavian',\n",
    "                                     'Western European','Irish','Scot - Irish','French-Canadian','Swiss/American',\n",
    "                                     'Eastern European', 'French Acadian'], 6)\n",
    "    \n",
    "    # Race Not on Application/ Not specified: 7 \n",
    "    df['Race'] = df['Race'].replace(['Prefer not to say', 'No Application - Letter Only','Not on Application', 'not latino or hispanic',\n",
    "                                     'not hispanic or lation','Not hispanic or Lation','not hispanice or latino',\n",
    "                                     'Not Hispnic or Latino', 'Not hispanic or Latino', 'Not Hispanice or Latino',\n",
    "                                     'Not Hispanic of Latino', 'Not Hispanic or Latino','Not hispanic or latino',\n",
    "                                     'nor hispanic or latino','not hispanic or latino','Not Hispanic or Lation',\n",
    "                                     'Not Hispanic or latino'], 7)\n",
    "    \n",
    "    # Mixed Nationality 8\n",
    "    df['Race'] = df['Race'].replace(['German/Irish American','Irish/American','Italian American','German / Slovak',\n",
    "                                     'Yugoslav / Swedish','Irish / Scottish / German', 'Chinese / German',\n",
    "                                     'European American','Scottish-German','English / Irish', 'French Canadian',\n",
    "                                     'French Canadian/American','Irish/Spanish','Irish / Mexican', 'Appalachian / American',\n",
    "                                     'Scotttish/Irish/Norwegian','Chinese/German','German / American',\n",
    "                                     'Irish/Italian/English/Dutch','Japanese / Scandinavian','Irish/Italian',\n",
    "                                     'Spanish/Italian','Italian / French', 'British / American','European / American',\n",
    "                                     'Italian / Portuguese / American', 'Mexican/Greek', 'Irish American',\n",
    "                                     'African / European / Carribean','Irish / American', 'Lebanese French Canadian',\n",
    "                                     'Korean / English','Western European / American'], 8)\n",
    "    \n",
    "    # Other: 9 \n",
    "    df['Race'] = df['Race'].replace(['Viking','Other','Elf','Human','other','Vikng','Pennsylvania Dutch','Texan','Yankee',\n",
    "                                     'Hawaiian','Melungeon','American','Angelic','Alaska Native','Jewish',\n",
    "                                     'American Mutt','Appalachian American', 'Polsih American'], 9)\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "clean_9(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I break this column up into North Americans, Europeans, Africans, Australians \n",
    "def clean_10(df):\n",
    "# North Americans \n",
    "    df['Country'] = df['Country'].replace(['USA','Canada','CANADA'],0)\n",
    "#Europeans\n",
    "    df['Country'] = df['Country'].replace(['England','Germany','France','HOLLAND','Austria',\n",
    "                                           'GERMANY','THE NETHERLANDS','Switzerland','SWITZERLAND',\n",
    "                                           'Ireland','Norway','ITALY','Finland','Sweden','Czech Republic'],1)\n",
    "# Oceania\n",
    "    df['Country'] = df['Country'].replace(['Australia','AUSTRALIA','New Zealand'],2)\n",
    "\n",
    "# African \n",
    "    df['Country'] = df['Country'].replace(['South Africa','Morocco (North Africa)'],3)\n",
    "\n",
    "# Other \n",
    "    df['Country'] = df['Country'].replace(['GUAM','Bahamas','India'],4)\n",
    "    \n",
    "\n",
    "clean_10(at)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_11(df):\n",
    "    df['Hike_Type'] = df['Hike_Type'].map({'NOBO':0, 'SOBO':1, 'Flip':2 })\n",
    "clean_11(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_12(df):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "clean_12(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finish</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Country</th>\n",
       "      <th>Hike_Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>completion_yr</th>\n",
       "      <th>HikedWDog</th>\n",
       "      <th>WinterHike</th>\n",
       "      <th>Under2KSpent</th>\n",
       "      <th>SchoolCredit</th>\n",
       "      <th>Minority</th>\n",
       "      <th>Vegetarian</th>\n",
       "      <th>DehydrateOwnFood</th>\n",
       "      <th>Giardia</th>\n",
       "      <th>Lyme</th>\n",
       "      <th>Norovirus</th>\n",
       "      <th>Total_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-12-31</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951-10-10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1951-05-30</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>133 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951-09-30</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1951-05-31</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>122 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959-09-17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1959-05-23</td>\n",
       "      <td>1959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>117 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965-09-23</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1965-04-16</td>\n",
       "      <td>1965</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>160 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Finish   Age  Race State  Sex  Country  Hike_Type      Start  \\\n",
       "0 1948-12-31  29.0     7    PA    0        0          0 1948-01-01   \n",
       "1 1951-10-10  28.0     7    CT    0        0          1 1951-05-30   \n",
       "2 1951-09-30  29.0     7    GA    0        0          0 1951-05-31   \n",
       "3 1959-09-17  20.0     0    GA    0        0          0 1959-05-23   \n",
       "4 1965-09-23  29.0     7    PA    0        0          1 1965-04-16   \n",
       "\n",
       "   completion_yr HikedWDog WinterHike Under2KSpent SchoolCredit Minority  \\\n",
       "0           1948     False      False        False        False    False   \n",
       "1           1951     False      False        False        False    False   \n",
       "2           1951     False      False        False        False    False   \n",
       "3           1959     False      False        False        False    False   \n",
       "4           1965     False      False        False        False    False   \n",
       "\n",
       "  Vegetarian DehydrateOwnFood Giardia   Lyme Norovirus  Total_Days  \n",
       "0      False            False   False  False     False    365 days  \n",
       "1      False            False   False  False     False    133 days  \n",
       "2      False            False   False  False     False    122 days  \n",
       "3      False            False   False  False     False    117 days  \n",
       "4      False            False   False  False     False    160 days  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AB': 9,\n",
       "         'AE': 3,\n",
       "         'AK': 48,\n",
       "         'AL': 149,\n",
       "         'AP': 1,\n",
       "         'AR': 39,\n",
       "         'AZ': 74,\n",
       "         'Au': 3,\n",
       "         'BC': 13,\n",
       "         'BY': 1,\n",
       "         'CA': 328,\n",
       "         'CH': 2,\n",
       "         'CO': 272,\n",
       "         'CT': 396,\n",
       "         'Ca': 4,\n",
       "         'Co': 2,\n",
       "         'Cu': 2,\n",
       "         'Cz': 2,\n",
       "         'DC': 43,\n",
       "         'DE': 48,\n",
       "         'En': 8,\n",
       "         'FL': 667,\n",
       "         'Fi': 1,\n",
       "         'Fr': 2,\n",
       "         'GA': 834,\n",
       "         'Ga': 1,\n",
       "         'Ge': 2,\n",
       "         'Gu': 1,\n",
       "         'HI': 21,\n",
       "         'Ha': 2,\n",
       "         'Ho': 1,\n",
       "         'IA': 64,\n",
       "         'ID': 26,\n",
       "         'IL': 239,\n",
       "         'IN': 225,\n",
       "         'Il': 1,\n",
       "         'Ir': 1,\n",
       "         'KS': 52,\n",
       "         'KY': 168,\n",
       "         'Ke': 2,\n",
       "         'LA': 72,\n",
       "         'La': 3,\n",
       "         'MA': 738,\n",
       "         'MB': 1,\n",
       "         'MD': 352,\n",
       "         'ME': 522,\n",
       "         'MI': 358,\n",
       "         'MN': 155,\n",
       "         'MO': 142,\n",
       "         'MS': 62,\n",
       "         'MT': 39,\n",
       "         'MY': 1,\n",
       "         'Ma': 2,\n",
       "         'Me': 1,\n",
       "         'Mi': 1,\n",
       "         'Mo': 1,\n",
       "         'NB': 12,\n",
       "         'NC': 798,\n",
       "         'ND': 9,\n",
       "         'NE': 25,\n",
       "         'NH': 426,\n",
       "         'NJ': 369,\n",
       "         'NL': 1,\n",
       "         'NM': 44,\n",
       "         'NP': 1,\n",
       "         'NS': 11,\n",
       "         'NV': 27,\n",
       "         'NY': 664,\n",
       "         'Ne': 4,\n",
       "         'No': 5,\n",
       "         'OH': 565,\n",
       "         'OK': 38,\n",
       "         'ON': 37,\n",
       "         'OR': 101,\n",
       "         'PA': 855,\n",
       "         'PE': 4,\n",
       "         'PR': 2,\n",
       "         'Pr': 1,\n",
       "         'QC': 17,\n",
       "         'Qu': 19,\n",
       "         'RI': 71,\n",
       "         'SC': 249,\n",
       "         'SD': 14,\n",
       "         'SK': 2,\n",
       "         'So': 4,\n",
       "         'Su': 3,\n",
       "         'Sw': 4,\n",
       "         'TN': 509,\n",
       "         'TX': 335,\n",
       "         'Ta': 2,\n",
       "         'UK': 1,\n",
       "         'UT': 45,\n",
       "         'VA': 840,\n",
       "         'VI': 1,\n",
       "         'VT': 186,\n",
       "         'WA': 132,\n",
       "         'WI': 189,\n",
       "         'WV': 91,\n",
       "         'WY': 15,\n",
       "         'We': 2,\n",
       "         'zz': 4})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(at['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [value for value in at.columns if value != 'Total_Days']\n",
    "X = at[features]\n",
    "y = at['Total_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-08888bd9312b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bweinstein413/anaconda/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bweinstein413/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/bweinstein413/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10,10))\n",
    "#null.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Null values by column \n",
    "#plt.figure(figsize = (10,10))\n",
    "#z = at.isnull().sum()\n",
    "#z.plot(kind = 'bar')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
