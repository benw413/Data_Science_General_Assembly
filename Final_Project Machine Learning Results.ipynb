{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Immesive Final Project (General Assembly ATX Spring 2017)\n",
    "### Can Machine Learning Predict Time on Trail for Appalachian Trail Thru hikers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Project Question: Can you predict how long it will take an Appalachian Trail Thru Hiker to complete the Appalachian Trail based on the features of this dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant information\n",
    "The data for my final project was obtained from the Appalachian Trail Conservancy (Harpers Ferry,WV).\n",
    "\n",
    "For the purposes of this project. I will exclude flip flops (only accounted for 1 data point in the data set) and thru-section hikes. A thru hike for the purposes of this project will be defined as the self reporting of that a hiker has created a continious footpath from Georgia to Maine or Maine to Georgia in a single hiking season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Table of Content: \n",
    "I explore the data column by column to understand what sort of missing or inaccurate values are contained.\n",
    "\n",
    "def (clean_1): Columns that can/will be dropped\n",
    "- Rename columns to be more accurate.\n",
    "- Drop 'Days Elapsed' column as it does not accuratly calculate the number of days on trail. (I replace this column in clean_2 with 'Total_Days')\n",
    "- Drop 'Hiking_Disability' Column as it was not well reported.\n",
    "- Drop Dog Weight Column (16238 of possible 17835 values were 0)\n",
    "- Drop columns with too many null values (columns that exceed 85 percent null values)\n",
    "- drop null values out of columns\n",
    "- **** come back to this Drop Under2kAmount column since (16125 out of 17835) values were 0 essentially the same as null values \n",
    "- Dropped 'Hiking \n",
    "\n",
    "\n",
    "def (clean_2/clean_3): Clean up the Age column \n",
    "- Fill null values in 'Age' column with median age.\n",
    "- All values below 4(There were some negative values) \n",
    "- The youngest person to thru-hike the AT is 5 so I assume all values above this are \n",
    "\n",
    " \n",
    "    \n",
    "def (clean_4): Datetime objects, \n",
    "-  Convert 'Start' and 'Finish' columns to Datetime objects\n",
    "-  Create a new column 'Total Days' that calculates total days on trail (at['Finish] - at['Start'])) \n",
    "-  There was as single null value in completion year, however, the finish date showed the hiker completed in 2016 so I changed the value to 2016 \n",
    "- I conveted the completion yr column from floats to ints \n",
    "- converted completion yr to a datetime object\n",
    "\n",
    "\n",
    "\n",
    "def (clean_5/clean_6): Clean 'Sex' column\n",
    "- In (clean_1) I dropped all null values in this column \n",
    "- Drop 'oher' and 'othe' out of the sex column\n",
    "- Convert the 'Sex' column to numerical format with the map function\n",
    "- Drop null values in the Sex column. There were only 2. \n",
    "- Converted M/F from float to int\n",
    "\n",
    "def (clean_7/clean_8): Clean 'Hike_Type' column (Drop section, alternative hikes, Yo Yo)\n",
    "- Drop values in the Hike column that are labeled alternative as I am unsure what these are and how to define them.\n",
    "- Since I am only interested in Thru Hikers and trying to predict time on trail based on people trying to hike in 6 months, and since all thru section hikers take varying amounts of time. \n",
    "- Difficult to estimate value for a Yo Yo so I dropped it, it was only a single column\n",
    "\n",
    "def (clean_9): Categorize the race column: Since the Data Set was very disorganized, Regular Expression\n",
    "was unable to take care of the categorization so I had to manually manipulate the categories\n",
    "- Caucasion variation = 0\n",
    "- African American Variation = 1\n",
    "- Asian Variation = 2\n",
    "- Hispanic Variation = 3\n",
    "- Native American = 4\n",
    "- Mixed Race: =5\n",
    "- European = 6\n",
    "- Mixed Race  = 7\n",
    "- European/Not American (You cannot assume they are white because they are European) = 8\n",
    "- Other = 9\n",
    "    \n",
    "\n",
    "def(clean_10): Group country of origin to express if they are North American, European, Australian,etc...\n",
    "- North American = 0 \n",
    "- European = 1 \n",
    "- Oceania = 2\n",
    "- African = 3\n",
    "\n",
    "def(clean_11): Convert Hike_Type values to numbers\n",
    "- 'NOBO':0\n",
    "- 'SOBO':1 \n",
    "- 'Flip':2 \n",
    "\n",
    "def (clean_12): Map Hike Types\n",
    "- NOBO = 0\n",
    "- SOBO = 1\n",
    "- Flip = 2\n",
    "\n",
    "def (clean_13): Convert Total_Days to an int\n",
    "\n",
    "\n",
    "def (clean_14): Drop Start and Finish Columns because you cannot pass datetime objects into your model\n",
    "\n",
    "\n",
    "\n",
    "def (clean_16): Reset Index \n",
    "- The index needed to be reset since I had dropped many rows containing null values \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do \n",
    "\n",
    "3.) Make Boolean columns into dummy variables \n",
    "\n",
    "7.) State \n",
    "\n",
    "8.) There are negative total days (str.replace values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "at = pd.read_excel('BenHikersInfo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17835, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finish</th>\n",
       "      <th>AgeYrFin</th>\n",
       "      <th>Race or Heritage</th>\n",
       "      <th>StAbbrev</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Country</th>\n",
       "      <th>Hike Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>Days Elapsed</th>\n",
       "      <th>Yr Comp</th>\n",
       "      <th>...</th>\n",
       "      <th>SchoolCredit</th>\n",
       "      <th>School</th>\n",
       "      <th>Minority</th>\n",
       "      <th>MinorityComments</th>\n",
       "      <th>Vegetarian</th>\n",
       "      <th>DehydrateOwnFood</th>\n",
       "      <th>Giardia</th>\n",
       "      <th>Lyme</th>\n",
       "      <th>Norovirus</th>\n",
       "      <th>Disease Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>10/10/1998</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>TX</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>3/20/1998</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>8 /15/1999</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>TX</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>3/15/1999</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>11/11/1999</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>TX</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>Flip</td>\n",
       "      <td>4/8/1999</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>9 /29/2000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>TX</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>4/3/2000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>10/1 /2001</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>TX</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>NOBO</td>\n",
       "      <td>3/31/2001</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Finish  AgeYrFin   Race or Heritage StAbbrev Sex Country Hike Type  \\\n",
       "4788  10/10/1998      24.0  Prefer not to say       TX   M     USA      NOBO   \n",
       "5069  8 /15/1999      24.0  Prefer not to say       TX   M     USA      NOBO   \n",
       "5470  11/11/1999      24.0  Prefer not to say       TX   M     USA      Flip   \n",
       "6135  9 /29/2000      24.0  Prefer not to say       TX   M     USA      NOBO   \n",
       "6494  10/1 /2001      24.0  Prefer not to say       TX   F     USA      NOBO   \n",
       "\n",
       "          Start  Days Elapsed  Yr Comp      ...      SchoolCredit School  \\\n",
       "4788  3/20/1998         205.0   1998.0      ...             False    NaN   \n",
       "5069  3/15/1999         154.0   1999.0      ...             False    NaN   \n",
       "5470   4/8/1999         218.0   1999.0      ...             False    NaN   \n",
       "6135   4/3/2000         180.0   2000.0      ...             False    NaN   \n",
       "6494  3/31/2001         185.0   2001.0      ...             False    NaN   \n",
       "\n",
       "     Minority MinorityComments  Vegetarian DehydrateOwnFood Giardia   Lyme  \\\n",
       "4788    False              NaN       False            False   False  False   \n",
       "5069    False              NaN       False            False   False  False   \n",
       "5470    False              NaN       False            False   False  False   \n",
       "6135    False              NaN       False            False   False  False   \n",
       "6494    False              NaN       False            False   False  False   \n",
       "\n",
       "     Norovirus Disease Other  \n",
       "4788     False           NaN  \n",
       "5069     False           NaN  \n",
       "5470     False           NaN  \n",
       "6135     False           NaN  \n",
       "6494     False           NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at[(at['AgeYrFin'] == 24) & (at['StAbbrev'] == 'TX')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_1(df):\n",
    "    df.drop(labels = df[['Disease Other','School','Hiking Disability','DogWeightLbs','Days Elapsed','MinorityComments','School',\n",
    "                         'DogBreed','Disability','Under2KAmount']], axis = 1, inplace = True)\n",
    "    df.rename(columns = {'AgeYrFin': 'Age','Race or Heritage': 'Race',\n",
    "                        'StAbbrev':'State', 'Hiking Disability ': 'Hiking_Disability', \n",
    "                         'Hike Type': 'Hike_Type', 'Yr Comp':'completion_yr',\n",
    "                         },inplace = True)\n",
    "    df.dropna(subset= ['Start','Sex','Race','Country','State','Hike_Type'],inplace = True)\n",
    "\n",
    "clean_1(at)  \n",
    "\n",
    "\n",
    "def clean_2(df):\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "clean_2(at)\n",
    "\n",
    "\n",
    "def clean_3(x,median_age): \n",
    "    if x < 4:\n",
    "        return median_age\n",
    "    else:\n",
    "        return x \n",
    "at['Age'] = at['Age'].apply(lambda x: clean_3(x, at['Age'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_4(df):\n",
    "    df['Finish'] = pd.to_datetime(df['Finish'])\n",
    "    df['Start'] = pd.to_datetime(df['Start'])\n",
    "    df['Total_Days'] = df['Finish'] - df['Start']\n",
    "    df['completion_yr'].fillna(2016,inplace = True)\n",
    "    df['completion_yr'] = df['completion_yr'].astype(int)\n",
    "clean_4(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_5(df):\n",
    "    #df['Sex'] = df['Sex'].map({'M':0,'F':1})\n",
    "    to_drop = ['othe','Oher']\n",
    "    x = df[df['Sex'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_5(at)\n",
    "\n",
    "# def clean_6(df):\n",
    "#     df.dropna(subset = ['Sex'], inplace = True)\n",
    "#     df['Sex'] = df['Sex'].astype(int)\n",
    "# clean_6(at)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_7(df):\n",
    "    to_drop = ['Alternative','alternative','Alterntive', 'Yo Yo']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_7(at)\n",
    "\n",
    "def clean_8(df):\n",
    "    to_drop = ['Section']\n",
    "    x = df[df['Hike_Type'].isin(to_drop)]\n",
    "    y = x.index\n",
    "    df.drop(y,inplace = True)\n",
    "clean_8(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    9977\n",
       "F    2964\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall to maintain original column \n",
    "def clean_9(df):\n",
    "    \n",
    "    # Caucasion Variation: 0 Identify Race Over Nationality/Religion \n",
    "    df['Race'] = df['Race'].replace(['White','WASP','Hewbrew/White','English','Caucasian / Viking',\n",
    "                                    'Caucasian or White','Caucasian or White/Irish','Caucasian / Polish / Irish',\n",
    "                                    'Caucasian / South Africaan','Caucasian or White/Amish','Caucasian / Irish'\n",
    "                                     'Caucasian or White/Jewish','Caucasian / Irish',\n",
    "                                     'Anglo Saxon / Scottish / American','Caucasian or White (Jewish)',\n",
    "                                     'Caucasian / European','Caucasian or White/Pacific Islander','Jewish/White',\n",
    "                                     'Caucasian or White/Jewish','Caucasian / non-Hispanic',\n",
    "                                     'Caucasian / Czech / Russian / German / English)','Anglo Saxon','White/Irish',\n",
    "                                     'White/Jewish','Caucasian/Lithuanian-American','White/Scandinavian','Caucasian',\n",
    "                                     'White/Pennsylvania Dutch','Caucasian / Irish / Nordic','Caucasian / Jewish',\n",
    "                                     'European/American', 'Caucasian / Polish','Caucasian / German',\n",
    "                                     'Caucasian / 1/4 German', 'Caucasian/French Canandien','Caucasian / Slovak','Mennowhite',\n",
    "                                     'White/Lebanese', 'White - Irish, Scot and Spanish', 'Caucasian / Italian / Eastern European',\n",
    "                                     'Caucasian / Bahamian', 'Caucasian / Haitian'], 'Caucasian')\n",
    "    # African American Variation: 1\n",
    "    df['Race'] = df['Race'].replace(['African American','African American/Biracial',], 'African_American')\n",
    "    \n",
    "    # Asian Variation: 2\n",
    "    df['Race'] = df['Race'].replace(['Asian','Chinese','Asian / Chinese','Vietnamese','Thai',\n",
    "                                    'Taiwanese / American','Asian / American','Korean/American','Japanese',\n",
    "                                    'Indian','Asian American','Korean / American','Asian (Indian/American)',\n",
    "                                    'Middle Eastern','Korean','Japanese/American','Caucasian / Asian / Pacific Islander',\n",
    "                                     'American Indian', 'Vietnamese American','Persian','Japanese / American', 'Pakistani',\n",
    "                                     'Tamil/Sri Lankan', 'Pacific Islander', 'Caucasian / Asian'], 'Asian')\n",
    "    # Hispanic/Latino: 3 I prioritize race over nationality \n",
    "    df['Race'] = df['Race'].replace(['Hispanic','Latino / Venzuelan','Japanese-American','Mexican / American',\n",
    "                                    'Mexican','Hispanic  / Colombian','Cuban','Latino','Puerto Rican',\n",
    "                                     'Hispanic or Latino','Mexican/American','Dominican','Hispanic / Mexican',\n",
    "                                    'Brazilian','Hispanic / Mexican / American','Hispanic/German', 'Hispanic / Italian',\n",
    "                                    ], 'Hispanic')\n",
    "    # Native American Variation: 4\n",
    "    df['Race'] = df['Race'].replace(['American Indian / Cherokee','Cherokee & English','Native American',\n",
    "                                    'Native American (1/2 cherokee) / 1/2 Celtic','American Indian / Choctaw'],'Native_America')\n",
    "    \n",
    "    # Mixed Race: 5 (remember to look at this in relation to all the mixed white people/lation peop)\n",
    "    df['Race'] = df['Race'].replace(['Mixed','mixed','Caucasian / Black / West Indian','Hispanic/Black','Black/White',\n",
    "                                    'Mix','Black and White','white/hispanic','White/Hispanic',\n",
    "                                     'Mutt','Black / Caucasian','European Mutt','White/Asian',\n",
    "                                     'White & African American','Caucasian / Chinese', 'Caucasian / Philipino',\n",
    "                                     'Hispanic or Latino; Mixed','Japanese/White','White/Latina','Hispanic/White',\n",
    "                                     'Latino/White', 'Caucasian/Hispanic','Hispanic / Caucasian','Caucasian/Pacific Islander',\n",
    "                                     'Filipino/Caucasian', 'African American/American Indian','White/Native American',\n",
    "                                     'Middle Easter/White', 'European/Native American', 'Caucasian / Brazilian',\n",
    "                                     'Asian / Pacific Islander / Hispanic', 'Caucasian / Hispanic', 'Caucasion/Filipino',\n",
    "                                     'American Indian / Caucasian', 'Lebanese / American','Caucasian / Pacific Islander',\n",
    "                                     'Navajo / Portugese','WASP / Italian'], 'Mixed_Race')\n",
    "    \n",
    "    # European: 6 (You cannot assume they are white because they are European)\n",
    "    df['Race'] = df['Race'].replace(['German','Italian','Polish','Dutch','European','Swiss','North European',\n",
    "                                    'Canadian','Finnish','german','Scottish','Ukrainian',\n",
    "                                    'Romanian','Bulgarian','Spanish','Lithuanian','British or English','Scandinavian',\n",
    "                                     'Western European','Irish','Scot - Irish','French-Canadian','Swiss/American',\n",
    "                                     'Eastern European', 'French Acadian'], 'European_National')\n",
    "    \n",
    "    # Race Not on Application/ Not specified: 7 \n",
    "    df['Race'] = df['Race'].replace(['Prefer not to say', 'No Application - Letter Only','Not on Application', 'not latino or hispanic',\n",
    "                                     'not hispanic or lation','Not hispanic or Lation','not hispanice or latino',\n",
    "                                     'Not Hispnic or Latino', 'Not hispanic or Latino', 'Not Hispanice or Latino',\n",
    "                                     'Not Hispanic of Latino', 'Not Hispanic or Latino','Not hispanic or latino',\n",
    "                                     'nor hispanic or latino','not hispanic or latino','Not Hispanic or Lation',\n",
    "                                     'Not Hispanic or latino'], 'Unspecified')\n",
    "    \n",
    "    # Mixed Nationality 8\n",
    "    df['Race'] = df['Race'].replace(['German/Irish American','Irish/American','Italian American','German / Slovak',\n",
    "                                     'Yugoslav / Swedish','Irish / Scottish / German', 'Chinese / German',\n",
    "                                     'European American','Scottish-German','English / Irish', 'French Canadian',\n",
    "                                     'French Canadian/American','Irish/Spanish','Irish / Mexican', 'Appalachian / American',\n",
    "                                     'Scotttish/Irish/Norwegian','Chinese/German','German / American',\n",
    "                                     'Irish/Italian/English/Dutch','Japanese / Scandinavian','Irish/Italian',\n",
    "                                     'Spanish/Italian','Italian / French', 'British / American','European / American',\n",
    "                                     'Italian / Portuguese / American', 'Mexican/Greek', 'Irish American',\n",
    "                                     'African / European / Carribean','Irish / American', 'Lebanese French Canadian',\n",
    "                                     'Korean / English','Western European / American'], 'Mixed_Nationality')\n",
    "    \n",
    "    # Other: 9 \n",
    "    df['Race'] = df['Race'].replace(['Viking','Other','Elf','Human','other','Vikng','Pennsylvania Dutch',\n",
    "                                     'Texan','Yankee',\n",
    "                                     'Hawaiian','Melungeon','American','Angelic','Alaska Native','Jewish',\n",
    "                                     'American Mutt','Appalachian American', 'Polsih American'], 'Other')\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "clean_9(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I break this column up into North Americans, Europeans, Africans, Australians \n",
    "def clean_10(df):\n",
    "# North Americans \n",
    "    df['Country'] = df['Country'].replace(['USA','Canada','CANADA'],'North American')\n",
    "#Europeans\n",
    "    df['Country'] = df['Country'].replace(['England','Germany','France','HOLLAND','Austria',\n",
    "                                           'GERMANY','THE NETHERLANDS','Switzerland','SWITZERLAND',\n",
    "                                           'Ireland','Norway','ITALY','Finland','Sweden','Czech Republic'],'European')\n",
    "# Oceania\n",
    "    df['Country'] = df['Country'].replace(['Australia','AUSTRALIA','New Zealand'],'Oceania/Australia')\n",
    "\n",
    "# African \n",
    "    df['Country'] = df['Country'].replace(['South Africa','Morocco (North Africa)'],'African')\n",
    "\n",
    "# Other \n",
    "    df['Country'] = df['Country'].replace(['GUAM','Bahamas','India'],'Other')\n",
    "    \n",
    "\n",
    "clean_10(at)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_11(df):\n",
    "#US states. I was able to grab a list of states from a python list off stack overflow\n",
    "    df['State'] = df['State'].replace([\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\",'Ca', 'Ga','Co','Me', ],0)\n",
    "# Non US states (I used the key from Collections import Counter model)\n",
    "    \n",
    "    df['State'] = df['State'].replace(['En', 'Ho', 'MY', 'SK', 'Ta', 'BY', 'ON', \n",
    "                                        'AP', 'NB', 'Cz', 'Ke', 'Ir', 'Sw', 'Ne', 'So', 'Ha', \n",
    "                                        'Gu', 'Fi', 'PR', 'QC', 'Cu', 'NL', 'No', 'NP', \n",
    "                                        'Il', 'AE', 'VI', 'Qu', 'Fr', 'Mo', 'Au', 'Su', 'We', \n",
    "                                        'Ma', 'NS', 'La', 'BC', 'zz', 'AB', 'PE', 'Mi', 'Ge', \n",
    "                                        'UK', 'Pr', 'MB', 'CH'],1)\n",
    "clean_11(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Finish', 'Age', 'Race', 'State', 'Sex', 'Country', 'Hike_Type',\n",
       "       'Start', 'completion_yr', 'HikedWDog', 'WinterHike', 'Under2KSpent',\n",
       "       'SchoolCredit', 'Minority', 'Vegetarian', 'DehydrateOwnFood', 'Giardia',\n",
       "       'Lyme', 'Norovirus', 'Total_Days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def clean_12(df):\n",
    "#     df['Hike_Type'] = df['Hike_Type'].map({'NOBO':0, 'SOBO':1, 'Flip':2 })\n",
    "# clean_12(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_13(df):\n",
    "    df['Start'] = df['Start'].dt.month\n",
    "    df['Finish'] = df['Finish'].dt.month\n",
    "\n",
    "clean_13(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Finish', 'Age', 'Race', 'State', 'Sex', 'Country', 'Hike_Type',\n",
       "       'Start', 'completion_yr', 'HikedWDog', 'WinterHike', 'Under2KSpent',\n",
       "       'SchoolCredit', 'Minority', 'Vegetarian', 'DehydrateOwnFood', 'Giardia',\n",
       "       'Lyme', 'Norovirus', 'Total_Days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_15(df):\n",
    "    df['Total_Days']= df['Total_Days'].dt.days\n",
    "\n",
    "clean_15(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_16(x):\n",
    "    if x == True:\n",
    "        return False\n",
    "    elif x == False:\n",
    "        return True\n",
    "\n",
    "at['Over2kSpent'] = at['Under2KSpent'].apply(clean_16)\n",
    "\n",
    "def clean_17(x):\n",
    "    if x == True:\n",
    "        return False\n",
    "    elif x == False:\n",
    "        return True\n",
    "at['SummerHike'] = at['WinterHike'].apply(clean_17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_18(x):\n",
    "    if 5 <= x < 15:\n",
    "        return '5-15'\n",
    "    elif  15 <= x < 25:\n",
    "        return '15-25'\n",
    "    elif  25 <= x < 35:\n",
    "        return '25-35'\n",
    "    elif  35 <= x < 45:\n",
    "        return '35-45'\n",
    "    elif  45 <= x < 55:\n",
    "        return '45-55'\n",
    "    elif  55 <= x < 65:\n",
    "        return '55-65'\n",
    "    elif  65 <= x < 75:\n",
    "        return '65-75'\n",
    "    elif  75 <= x < 85:\n",
    "        return '75-85'\n",
    "    elif  x >= 85:\n",
    "        return '85 and older'\n",
    "at['Age'] = at['Age'].apply(clean_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_sex = pd.get_dummies(at[['Sex','Country','Race','Hike_Type','Age']])\n",
    "at_new = pd.concat([at.drop(['Sex','Country','Race','Hike_Type','Age'],axis =1),dummies_sex],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Country_African</th>\n",
       "      <th>Country_European</th>\n",
       "      <th>Country_North American</th>\n",
       "      <th>Country_Oceania/Australia</th>\n",
       "      <th>Country_Other</th>\n",
       "      <th>Race_African_American</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>Race_Caucasian</th>\n",
       "      <th>...</th>\n",
       "      <th>Hike_Type_NOBO</th>\n",
       "      <th>Hike_Type_SOBO</th>\n",
       "      <th>Age_15-25</th>\n",
       "      <th>Age_25-35</th>\n",
       "      <th>Age_35-45</th>\n",
       "      <th>Age_45-55</th>\n",
       "      <th>Age_5-15</th>\n",
       "      <th>Age_55-65</th>\n",
       "      <th>Age_65-75</th>\n",
       "      <th>Age_75-85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sex_F  Sex_M  Country_African  Country_European  Country_North American  \\\n",
       "8     0.0    1.0              0.0               0.0                     1.0   \n",
       "9     0.0    1.0              0.0               0.0                     1.0   \n",
       "10    0.0    1.0              0.0               0.0                     1.0   \n",
       "20    0.0    1.0              0.0               0.0                     1.0   \n",
       "36    0.0    1.0              0.0               0.0                     1.0   \n",
       "\n",
       "    Country_Oceania/Australia  Country_Other  Race_African_American  \\\n",
       "8                         0.0            0.0                    0.0   \n",
       "9                         0.0            0.0                    0.0   \n",
       "10                        0.0            0.0                    0.0   \n",
       "20                        0.0            0.0                    0.0   \n",
       "36                        0.0            0.0                    0.0   \n",
       "\n",
       "    Race_Asian  Race_Caucasian    ...      Hike_Type_NOBO  Hike_Type_SOBO  \\\n",
       "8          0.0             0.0    ...                 1.0             0.0   \n",
       "9          0.0             0.0    ...                 0.0             1.0   \n",
       "10         0.0             0.0    ...                 1.0             0.0   \n",
       "20         0.0             1.0    ...                 1.0             0.0   \n",
       "36         0.0             0.0    ...                 0.0             1.0   \n",
       "\n",
       "    Age_15-25  Age_25-35  Age_35-45  Age_45-55  Age_5-15  Age_55-65  \\\n",
       "8         0.0        1.0        0.0        0.0       0.0        0.0   \n",
       "9         0.0        1.0        0.0        0.0       0.0        0.0   \n",
       "10        0.0        1.0        0.0        0.0       0.0        0.0   \n",
       "20        1.0        0.0        0.0        0.0       0.0        0.0   \n",
       "36        0.0        1.0        0.0        0.0       0.0        0.0   \n",
       "\n",
       "    Age_65-75  Age_75-85  \n",
       "8         0.0        0.0  \n",
       "9         0.0        0.0  \n",
       "10        0.0        0.0  \n",
       "20        0.0        0.0  \n",
       "36        0.0        0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_20(df):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "clean_20(at_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finish</th>\n",
       "      <th>State</th>\n",
       "      <th>Start</th>\n",
       "      <th>completion_yr</th>\n",
       "      <th>HikedWDog</th>\n",
       "      <th>WinterHike</th>\n",
       "      <th>Under2KSpent</th>\n",
       "      <th>SchoolCredit</th>\n",
       "      <th>Minority</th>\n",
       "      <th>Vegetarian</th>\n",
       "      <th>...</th>\n",
       "      <th>Hike_Type_NOBO</th>\n",
       "      <th>Hike_Type_SOBO</th>\n",
       "      <th>Age_15-25</th>\n",
       "      <th>Age_25-35</th>\n",
       "      <th>Age_35-45</th>\n",
       "      <th>Age_45-55</th>\n",
       "      <th>Age_5-15</th>\n",
       "      <th>Age_55-65</th>\n",
       "      <th>Age_65-75</th>\n",
       "      <th>Age_75-85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1951</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1965</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Finish  State  Start  completion_yr HikedWDog WinterHike Under2KSpent  \\\n",
       "0      12      0      1           1948     False      False        False   \n",
       "1      10      0      5           1951     False      False        False   \n",
       "2       9      0      5           1951     False      False        False   \n",
       "3       9      0      5           1959     False      False        False   \n",
       "4       9      0      4           1965     False      False        False   \n",
       "\n",
       "  SchoolCredit Minority Vegetarian    ...     Hike_Type_NOBO Hike_Type_SOBO  \\\n",
       "0        False    False      False    ...                1.0            0.0   \n",
       "1        False    False      False    ...                0.0            1.0   \n",
       "2        False    False      False    ...                1.0            0.0   \n",
       "3        False    False      False    ...                1.0            0.0   \n",
       "4        False    False      False    ...                0.0            1.0   \n",
       "\n",
       "  Age_15-25 Age_25-35  Age_35-45 Age_45-55 Age_5-15  Age_55-65  Age_65-75  \\\n",
       "0       0.0       1.0        0.0       0.0      0.0        0.0        0.0   \n",
       "1       0.0       1.0        0.0       0.0      0.0        0.0        0.0   \n",
       "2       0.0       1.0        0.0       0.0      0.0        0.0        0.0   \n",
       "3       1.0       0.0        0.0       0.0      0.0        0.0        0.0   \n",
       "4       0.0       1.0        0.0       0.0      0.0        0.0        0.0   \n",
       "\n",
       "   Age_75-85  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_new['Total_Days'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [value for value in at_new.columns if value != 'Total_Days' and value != 'Start' and value != 'Finish']\n",
    "X = at_new[features]\n",
    "y = at_new['Total_Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>-0.949887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completion_yr</th>\n",
       "      <td>-3.083384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HikedWDog</th>\n",
       "      <td>14.350401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WinterHike</th>\n",
       "      <td>18.352690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under2KSpent</th>\n",
       "      <td>-5.230520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SchoolCredit</th>\n",
       "      <td>-10.942790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minority</th>\n",
       "      <td>5.098544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vegetarian</th>\n",
       "      <td>-3.856365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DehydrateOwnFood</th>\n",
       "      <td>6.446468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giardia</th>\n",
       "      <td>18.732793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lyme</th>\n",
       "      <td>9.436169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norovirus</th>\n",
       "      <td>63.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over2kSpent</th>\n",
       "      <td>5.230520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummerHike</th>\n",
       "      <td>-18.352690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_F</th>\n",
       "      <td>2.998147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_M</th>\n",
       "      <td>-2.998147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_African</th>\n",
       "      <td>-40.622924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_European</th>\n",
       "      <td>25.704247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_North American</th>\n",
       "      <td>4.548415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Oceania/Australia</th>\n",
       "      <td>-17.627881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Other</th>\n",
       "      <td>27.998143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_African_American</th>\n",
       "      <td>-7.946255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Asian</th>\n",
       "      <td>-7.636538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Caucasian</th>\n",
       "      <td>-1.026267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_European_National</th>\n",
       "      <td>-7.399410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <td>-4.938119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Mixed_Nationality</th>\n",
       "      <td>9.160922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Mixed_Race</th>\n",
       "      <td>7.929806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Native_America</th>\n",
       "      <td>9.531796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Other</th>\n",
       "      <td>6.517455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Unspecified</th>\n",
       "      <td>-4.193389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hike_Type_Flip</th>\n",
       "      <td>23.495727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hike_Type_NOBO</th>\n",
       "      <td>-9.060082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hike_Type_SOBO</th>\n",
       "      <td>-14.435644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_15-25</th>\n",
       "      <td>-19.619805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_25-35</th>\n",
       "      <td>5.876327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_35-45</th>\n",
       "      <td>-12.872330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_45-55</th>\n",
       "      <td>-11.274921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_5-15</th>\n",
       "      <td>-0.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_55-65</th>\n",
       "      <td>-6.377255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_65-75</th>\n",
       "      <td>2.761666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_75-85</th>\n",
       "      <td>41.566719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                coef\n",
       "State                      -0.949887\n",
       "completion_yr              -3.083384\n",
       "HikedWDog                  14.350401\n",
       "WinterHike                 18.352690\n",
       "Under2KSpent               -5.230520\n",
       "SchoolCredit              -10.942790\n",
       "Minority                    5.098544\n",
       "Vegetarian                 -3.856365\n",
       "DehydrateOwnFood            6.446468\n",
       "Giardia                    18.732793\n",
       "Lyme                        9.436169\n",
       "Norovirus                  63.276600\n",
       "Over2kSpent                 5.230520\n",
       "SummerHike                -18.352690\n",
       "Sex_F                       2.998147\n",
       "Sex_M                      -2.998147\n",
       "Country_African           -40.622924\n",
       "Country_European           25.704247\n",
       "Country_North American      4.548415\n",
       "Country_Oceania/Australia -17.627881\n",
       "Country_Other              27.998143\n",
       "Race_African_American      -7.946255\n",
       "Race_Asian                 -7.636538\n",
       "Race_Caucasian             -1.026267\n",
       "Race_European_National     -7.399410\n",
       "Race_Hispanic              -4.938119\n",
       "Race_Mixed_Nationality      9.160922\n",
       "Race_Mixed_Race             7.929806\n",
       "Race_Native_America         9.531796\n",
       "Race_Other                  6.517455\n",
       "Race_Unspecified           -4.193389\n",
       "Hike_Type_Flip             23.495727\n",
       "Hike_Type_NOBO             -9.060082\n",
       "Hike_Type_SOBO            -14.435644\n",
       "Age_15-25                 -19.619805\n",
       "Age_25-35                   5.876327\n",
       "Age_35-45                 -12.872330\n",
       "Age_45-55                 -11.274921\n",
       "Age_5-15                   -0.060400\n",
       "Age_55-65                  -6.377255\n",
       "Age_65-75                   2.761666\n",
       "Age_75-85                  41.566719"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable increases time by x amount \n",
    "results = pd.DataFrame(lm.coef_, features, columns = ['coef'] )\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12581394792929979"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
